title: 神经网络入门
author: jianmingYuan
date: 2024-03-01 15:04:38
tags:
---
# 何为张量？

> 仅包含一个数字的张量叫做标量（`scalar`也叫标量, 零维张量,**0D张量**）。
> 在`Numpy`中，一个`float32`或者`float64`的数字就是一个标量张量（或者标量数组）。你可以用`ndim`属性
> 来查看张量的轴数.

## 0D张量（标量）
```ptyhon
np.array(12)
```
## 1D张量（向量）
```python
np.array([12,3,6,14,7])
```
## 2D张量（矩阵）
```python
#表示3x5长度的矩阵
np.array([[12,3,6,14,7],[6,79,3,35,1],[7,80,4,36,2]])
```
## 3D张量和更高维的张量
- 5D向量–表示一个轴有五个数值
- 5D张量–表示有五个轴
```python
np.array([
        [[12,3,6,14,7],[6,79,3,35,1],[7,80,4,36,2]],
        [[12,3,6,14,7],[6,79,3,35,1],[7,80,4,36,2]],
        [[12,3,6,14,7],[6,79,3,35,1],[7,80,4,36,2]]
      ])
```
## 张量的关键属性
- ndim（轴的个数）
- 形状 => 3D形状(3,3,5)=>表示3个3x5的矩阵
- 数据类型–`float32`(例如：MINIST的数据集为由8位整数组成的3D张量,每个矩阵都表示为灰度图像)
```python
  ###从train_image数据集中抽（90,28,28）的图像
  train_image[10:100]==train_image[10:100,:,:]==train_image[10:100,0:28,0:28]
  ####截取所有图片14x14的图像
  train_image[:,14:,14:]
  ####截取所有图片中心截取14x14的图像
  train_image[:,7:-7,7:-7]
```
## 现实中物体如何用张量表示
- 向量数据：2D–形状(samples,features)
- 时间序列或序列数据：3D张量, (samples,timesteps,features)
- 图像：4D –(samples,height,width,channels)
- 视频:5D –(samples,frames,height,width,channels)
## 训练模型用到哪些数据集
### 数据集
1. 非张量数据类型需要做数据转换，实际操作例如
```python
mean=train_data.mean(axis=0)
train_data-=mean
std=train_data.std(axis=0)
train_data/ =std

test_data-=mean
test_data/=std
```
### 训练集
1. 训练集留出验证集来防止信息泄露
```python
num_validation_samples=10000
##需要打乱数据
np.random.suffle(data)
##定义验证集
validatation_data=data[:numvalidation_samples]
data=data[num_validation_samples:]
   ##定义训练集
 training_data=data[:]
 训练集训练模型
 验证集评估模型
 model=get_model()
 model.train(training_data)
 validation_score=model.evaluate(validation_data)
 #现在你可以调节模型、重新训练、评估，然后再次调节....
 model=get_model()                   					   			model.train(np.concatence([training_data,validation_data]))
  test_score=model.evaluate(test_data)
 ###一旦调节号超参数，通常就在所有非测试数据上从头开始训练最终模型
```
2. 训练过程超参数调优
   - 使用tensorBoard和keras可视化训练过程
   - 使用批量和小批量工作 –早停方法防止过拟合
   - 使用网格搜索调整参数 –Hyperopt
   - 学习率和学习率调度
   - 比较优化器
   - 确定网络的深度
   - 添加Dropout以防止过拟合
   - 通过数据增广使模型更好
   - 利用TTA来提高精度
3. 利用keras框架中的tensorBoard`callbacks=[EarlyStopping()]回调函数`
4. 分析网络内部结构
   - 用tensorBoard可视化训练结构
   - 用tensorBoard可视化网络结构
   - 分析网络权重
   - 冻结层
   - 存储网络结构并训练权重

### 验证集
1. 通过K折验证算法打乱验证集
```python
k=4
num_validation_samples=len(data) //k
np.random.shuffle(data)
validation_scores=[]
for fold in range(k):
###选择验证集区域
    validation_data=data[num_validaion_samples * fold:
    num_validation_samples*(fold+1)]
    ###使用剩余数据作为训练数据，注意，+运算符是列表合并，不是求和
    train_data=data[:num_validation_samples*fold]+data[num_validation_samples*(fold+1):]
    ##创建一个全新的模型
    model=get_model()
    model.train(training_data)
    validation_score=model.evaluate(validation_data)
    validation_scores.append(validation_score)
    ##k折取平均值
    validation_score=np.average(validation_scores)
 #在非测试集上训练最终的模型
 model=get_model()
 model.train(data)
 test_score=model.evaluate(test_data)
```
# 层
> 包含数据的变换和权重

## 如何定义输入层和输出层
```python
####输出32个密集层
model.add(Dense(32,input_shape=784))
####默认为上一个输出层的输出当作下一层输入
model.add(Dense(32))
```

## 层在训练过程如何优化
在训练的过程中需要将损失函数（目标函数）最小化，不同的训练类型有不同的处理
1. 二类分类（binary cossentropy）
2. 多分类(categorial cossentropy)
  - 采用优化器（`adm，rmsprop，sgd`）提高学习率
3. 回归问题(mean-squared error)
  - 采用激活函数将线性转为非线性
4. 联结主义时序分类(CTC)
6. 其他场景
  - 将整数数列编码为二进制矩阵
  
  ```python
  def vectorize_sequences(sequences,dimension=10000):
    #零矩阵
    res=np.zeros((len(sequences),dimension))
    for i,sequences in enumerate(sequences)：
     #res[i]的制定索引设为1
     res[i,sequences]=1
  ###标签向量化
  np.asarray(train_lables).astype('float32')
  ```
  - 绘制训练损失和验证损失数据分析图防止过拟合
  
    ```python
        import matplotlib.pyplot as plt
        history_dic=history.history
        loss_values=history_dic['loss']
        val_loss_values=history_dic['val_loss']

        epochs=range(1,len(loss_values)+1)

        plt.plot(epochs,loss_values,'bo',label='training loss')
        plt.plot(epochs,loss_values,'b',label='val loss')
        plt.title("loss")
        plt.xlabes("epochs")
        plt.xlabes("loss")
        plt.legend()
        plt.show()
  ```
  
 # 卷积神经网络
 ## 如何定义卷积的参数
 - 从输入中提取的图块尺寸–3x3
 
 - 输出特征图的深度，例如第一层深度32
 
 - 输出的高度和宽度可与输入的宽度和高度不同，不同的原因有两点
     1. 边界效应–可以输入特征图进行填充
     2. 输出特征图的空间维度与输入相同–使用填充（padding）
     3. 最大池化运算
 - 数据预处理
  
  ```python
      from keras.preprocessing.image import ImageDateGenerator
      ###将所以图像乘以1/255缩放
      train_datagen=ImageDataGenerator(rescale=1./255)
      test_datagen=ImageDataGenerator(rescale=1./255)
       train_generator=train_datagen.flow_from_directory(
         train_dir,##目标目录
         target_size=(150,150),##将所以图像大小调整150x150
         batch_size=20,
         class_mode='binary'###因为用到binary_crossentropy
       )
       valiation_generator=test_datagen.flow_from_directory(
         train_dir,##目标目录
         target_size=(150,150),##将所以图像大小调整150x150
         batch_size=20,
         class_mode='binary'###因为用到binary_crossentropy
       )
       ##python 生成器
       history=model.fit_generator(
         train_generator,
         steps_per_epoch=100,
         epochs=30,
         validation_data=validatation_generator,
         validation_steps=50
       )

  ```
## 如何使用预训练的卷积神经网络
### 特征提取

> 特征提取就是提取之前训练好的网络的卷积基，在上面运行新的数据，然后再输出的上面训练一个新的分类器
1. VGG16模型参数详解
 - weights：模块初始化检查点
 - include_top: 是否使用自带的密集器
 - input_shape: 网络输入图像的形状，可选–处理任意的图像形状
 
例如：使用数据增强的特征提取–建议运行GPU上
```python
  from keras import models
  from keras import layers

  model=model.Sequential()
  model.add(conv_base)
  model.add(layers.Flatten())
  model.add(layers.Dense(256,activatiion='relu'))
  model.add(layers.Dense(256,activatiion='softmax'))
  ##在keras中，冻结网络的方法是将其trainable属性设置为false

  conv_base.trainable=false
  ##编译使其生效

  ##数据增加
  .......
```
2. 微调模型

微调是指将其顶部的几层解冻，并将折解冻的几层和新增加的部分联合训练，在已经训练好的基网络上添加自定义网络，冻结基网络，训练所添加的部分，解冻基网络的一些层，联合训练解冻的这些层和添加的部分

```python
###冻结直到某一层的所有层
conv_base.trainable=true
set_trainable=false
for layer in conv_base.layers:
    if layer.name == 'block5_conv1':
       set_trainable=True
     if set_trainable:
        layer.trainable=true
       else:
         layer.trainable=false      
##微调模型
  model.compile(
  loss='binary_crossentropy',
  optimizer=optimizers.RMSprop(lr=1e-5),
  metrics=['acc'])
  history=model.fit_generator(
    train_generator,
    steps_per_epoch=100,
    epochs=100,
    validation_data=validation_generator,
    validation_steps=50
  )
```
## 卷积神经网络的可视化

- 可视化卷积神经网络的中间输出（中间激活）:有助于理解卷积神经网络连续的层如何对输入进行变换，也有助于初步了解卷积网络每个过滤器的含义
- 可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的视觉模式或视觉概念
- 可视化图像中类激活的热力图：有助于理解图像的那个部分被识别为属于某个类别，从而可以定位图像的物体—特别用于分类出错的情况

## 应用场景
1. 实时检测框架，能够快速的检测物体的模型
   - faster-RCNN –精准
   - YOKLO –更快检测
   - SSD –单发多盒检测器
2. 训练图像的掩膜
```python
  n_examples=3
  for i in range(n_examples):
     plt.subplot(2,2,1)
     image=cv2.imread(filename[i])
     image=cv2.cvtColor(image,cv2.COLOR_RGB2RGB)
     plt.imshow(image)

     plt.subplot(2,2,2)
     mask_file=filename[i].replace('src_color','human_seg')
     mask=cv2.imread(glob.glob(mask_file[:-4]+'*')[0])
     ret,mask=cv2.threshold(mask,0.255,cv2.THRESH_BINARY_INV)
     mask=mask[:0]
     plt.imshow((mask),camp='gray')

     plt.show()
```
3. 图像分割分类—U-net
4. 寻找人脸面部关键点
  - 传统计算机视觉中最常用的应用之一时检测图像中的人脸
  - 第一步检测图像（或帧）中的面部关键点
  - HOG+线性SVM等传统计算机视觉技术和机器学习技术任然被使用
  - 头部姿态、脸部变形以及使用opencv进行跟踪

# 总结
1. 带有relu的dense层堆叠，可以解决很多种问题（包括情感分析问题）

2. 对于二类问题（两个输出类别），网络的最后一层应该是只有一个单元使用sigmoid激活的dense层，网络输出应该是0-1范围内的标量，表示概率

3. 对于二分类问题的sigmoid标量输出，你应该使用binary_cossesntropy损失函数

4. 无论你的问题是什么，rmsprop优化器通常都是足够号的选择。这一点无须担心。

5. 如果要对n个类别的数据点进行分类，那么最后一层应该是n个dense层

6. 对于单标签。多分类问题，网络的最后一层应该使用softmax函数激活，输出类别的概率分布

7. 处理多分类问题的标签有两种方法

8. 分类编码（one-hot编码）对标签进行编码（y_lables）然后使用categorical_crossentropy作为损失函数
将标签编码为整数，然后使用spare_categroical_crossentropy损失函数
如果你需要将数据划分到许多分类种，应该避免使用太小的中间层，以免网络中造成信息瓶颈

9. 题使用的损失函数与分类问题不同。回归常用的损失函数是均方差。

10. 归问题使用的评估指标也与分类问题不同，显而易见，精度的概念不适用于回归问题。常见的回归指标是平均绝对误差（mae）

11. 数据的特征具有不同的取值范围，应该先进行预处理，对每个特征单独进行缩放

12. 的数据很少，使用k折验证可以可靠的评估模型

13. 的训练很少，最好使用隐藏层较少（通常只有一到两个的小型网络），以避免过拟合

14. 评估模型注意点

    - 数据代表性–随机打乱数据
    - 时间箭头–不可打乱数据，测试机的时间晚于训练集的数据
    - 数据冗余–训练集和数据集不能有交集
    - 数据标准化–每个特征的取值范围不一致

15. 数据必须向量化

16. 处理缺失值–不是所有样本都有这个特征

17. 无法确认模型是否强大–就必须开发过拟合的模型

    - 添加更多的层
    - 让每一层变得更大
    - 训练更多的轮次
    - 出现过拟合然后进行优化和调参，监督其参数的变化

